{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:50:05.645040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-04 17:50:06.448484: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-04 17:50:06.662766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-04 17:50:08.263551: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 17:50:15.791852: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Base python imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Assuming the notebook is located in <ROOT>/notebooks\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "#PyPi imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom imports\n",
    "from src.modeling.utils.OpticalFlowUtils import FlowReader\n",
    "from src.modeling.utils.OpticalFlowUtils import FlowVisualiser\n",
    "from src.modeling.utils.MPISintelUtils import MPISintelHandler\n",
    "from src.modeling.customML.customLosses.CustomLosses import EPE_Loss\n",
    "from src.modeling.customML.customModels.OpticalFlowUnrolling import UnrolledOFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU(s): [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "GPU(s): [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722765029.716036  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.044226  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.044274  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.048305  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.048376  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.048400  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.187742  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-04 17:50:32.187771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1722765032.187820  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722765032.187850  461414 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-04 17:50:32.191116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPU(s): {gpus}\")\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 8.1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=1024*8.0)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "        print(f\"GPU(s): {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(f\"Runtime Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FlowReader()\n",
    "visualiser = FlowVisualiser()\n",
    "dataHandler = MPISintelHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sintel images shape: (1041, 2, 436, 1024)\n",
      "Sintel flows shape: (1041, 436, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "RAW_DATA_PATH = os.path.join(\"..\", \"data\", \"raw\")\n",
    "PROCESSED_DATA_PATH = os.path.join(\"..\", \"data\", \"processed\")\n",
    "\n",
    "IMAGES_PATH = os.path.join(PROCESSED_DATA_PATH, \"trainImages.data\")\n",
    "FLOWS_PATH = os.path.join(PROCESSED_DATA_PATH, \"trainFlows.data\")\n",
    "\n",
    "trainImgsArray = dataHandler.loadData(IMAGES_PATH)\n",
    "trainFlowsArray = dataHandler.loadData(FLOWS_PATH)\n",
    "\n",
    "print(f\"Sintel images shape: {trainImgsArray.shape}\")\n",
    "print(f\"Sintel flows shape: {trainFlowsArray.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:50:53.023569: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1821573120 exceeds 10% of free system memory.\n",
      "2024-08-04 17:51:03.460609: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1060798464 exceeds 10% of free system memory.\n",
      "2024-08-04 17:51:09.947576: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 835780608 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_IMAGES_PATH = os.path.join(PROCESSED_DATA_PATH, \"trainX.data\")\n",
    "TRAIN_FLOWS_PATH = os.path.join(PROCESSED_DATA_PATH, \"trainy.data\")\n",
    "\n",
    "train_X = dataHandler.loadData(TRAIN_IMAGES_PATH)\n",
    "train_X = train_X.astype('float32') / 255.0\n",
    "train_X = tf.reshape(train_X, shape=(-1, 2, 436, 1024, 1))\n",
    "\n",
    "train_y = dataHandler.loadData(TRAIN_FLOWS_PATH)\n",
    "train_y = train_y.astype('float32')\n",
    "\n",
    "TEST_IMAGES_PATH = os.path.join(PROCESSED_DATA_PATH, \"testX.data\")\n",
    "TEST_FLOWS_PATH = os.path.join(PROCESSED_DATA_PATH, \"testy.data\")\n",
    "\n",
    "test_X = dataHandler.loadData(TEST_IMAGES_PATH)\n",
    "test_X = test_X.astype('float32') / 255.0\n",
    "test_X = tf.reshape(test_X, shape=(-1, 2, 436, 1024, 1))\n",
    "\n",
    "test_y = dataHandler.loadData(TEST_FLOWS_PATH)\n",
    "test_y = test_y.astype('float32')\n",
    "\n",
    "VAL_IMAGES_PATH = os.path.join(PROCESSED_DATA_PATH, \"valX.data\")\n",
    "VAL_FLOWS_PATH = os.path.join(PROCESSED_DATA_PATH, \"valy.data\")\n",
    "\n",
    "val_X = dataHandler.loadData(VAL_IMAGES_PATH)\n",
    "val_X = val_X.astype('float32') / 255.0\n",
    "val_X = tf.reshape(val_X, shape=(-1, 2, 436, 1024, 1))\n",
    "\n",
    "val_y = dataHandler.loadData(VAL_FLOWS_PATH)\n",
    "val_y = val_y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: (510, 2, 436, 1024, 1) test_X: (297, 2, 436, 1024, 1) val_X: (234, 2, 436, 1024, 1) -> Total Samples: 1041\n",
      "train_y: (510, 436, 1024, 2) test_y: (297, 436, 1024, 2) val_y: (234, 436, 1024, 2) -> Total Samples: 1041\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_X: {train_X.shape} test_X: {test_X.shape} val_X: {val_X.shape} -> Total Samples: {train_X.shape[0] + test_X.shape[0] + val_X.shape[0]}\")\n",
    "print(f\"train_y: {train_y.shape} test_y: {test_y.shape} val_y: {val_y.shape} -> Total Samples: {train_y.shape[0] + test_y.shape[0] + val_y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UnrollingOF\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"UnrollingOF\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ DataTermLayer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_10                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_11                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_12                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_13                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_14                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_15                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_1       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_2       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_3       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_4       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_5       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_6       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_7       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_8       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_9       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_10      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_11      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_12      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_13      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_14      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_15      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ DataTermLayer_1 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_2 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_3 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_4 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_5 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_6 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_7 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_8 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_9 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_10                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_11                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_12                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_13                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_14                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_15                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_1       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_2       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_3       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_4       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_5       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_6       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_7       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_8       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_9       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_10      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_11      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_12      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_13      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_14      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_15      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = UnrolledOFModel(num_iterations = 15, name = \"UnrollingOF\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"..\", \"assets\", \"logs\", \"fits\", f\"{model.name}_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_images=True)\n",
    "\n",
    "modelDir = os.path.join(\"..\", \"assets\", \"ml\", \"models\", model.name)\n",
    "if not os.path.exists(modelDir):\n",
    "    os.makedirs(modelDir)\n",
    "\n",
    "modelPath = os.path.join(modelDir, f\"{model.name}_best.weights.h5\")\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=modelPath, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "learning_rate_callback = tf.keras.callbacks.ReduceLROnPlateau(factor=0.85, patience=50, min_lr=1e-6)\n",
    "_callbacks = [tensorboard_callback, model_checkpoint_callback, learning_rate_callback]\n",
    "\n",
    "callbacks = tf.keras.callbacks.CallbackList(_callbacks, add_history=False)\n",
    "\n",
    "fileWriter = tf.summary.create_file_writer(os.path.join(log_dir, \"metrics\"))\n",
    "fileWriter.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/a/OneDrive/Repos/PIOFE-Unrolling/.venv-linux/lib/python3.10/site-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'UnrollingOF', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"UnrollingOF\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"UnrollingOF\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ DataTermLayer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_10                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_11                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_12                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_13                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_14                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_15                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DataTermLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_1       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_2       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_3       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_4       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_5       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_6       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_7       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_8       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_9       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_10      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_11      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_12      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_13      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_14      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_15      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RegularisationTermLayer</span>)       │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ DataTermLayer_1 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_2 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_3 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_4 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_5 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_6 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_7 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_8 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_9 (\u001b[38;5;33mDataTermLayer\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_10                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_11                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_12                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_13                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_14                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DataTermLayer_15                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mDataTermLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_1       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_2       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_3       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_4       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_5       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_6       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_7       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_8       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_9       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_10      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_11      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_12      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_13      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_14      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ RegularisationTermLayer_15      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mRegularisationTermLayer\u001b[0m)       │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=EPE_Loss(), metrics = ['mse'])\n",
    "model.build(input_shape=(None, 2, 436, 1024, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 17:51:14.471533: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1821573120 exceeds 10% of free system memory.\n",
      "2024-08-04 17:51:15.296905: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1821573120 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/a/OneDrive/Repos/PIOFE-Unrolling/.venv-linux/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722765080.392279  463639 service.cc:146] XLA service 0x7fd620039490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722765080.392331  463639 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-08-04 17:51:21.930762: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-04 17:51:23.109506: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722765085.587105  463639 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - loss: 114.9928 - mse: 47022.5703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 2/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.2512 - mse: 46881.2070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 3/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.3114 - mse: 47049.2148 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 4/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0853 - mse: 44939.7148 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 5/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1947 - mse: 44891.0039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 6/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8209 - mse: 46302.5820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 7/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.6285 - mse: 47925.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 8/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8939 - mse: 46672.6914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 9/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4279 - mse: 44336.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 10/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2440 - mse: 45989.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 11/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6885 - mse: 44973.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 12/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8235 - mse: 43460.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 13/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.8097 - mse: 45570.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 14/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4513 - mse: 42797.1289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 15/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9777 - mse: 46525.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 16/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4941 - mse: 42444.9375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 17/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.0329 - mse: 45376.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 18/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.9398 - mse: 44854.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 19/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8642 - mse: 46811.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 20/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5865 - mse: 45866.4570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 21/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4224 - mse: 45505.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 22/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3086 - mse: 46435.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 23/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0627 - mse: 43549.2031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 24/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.3702 - mse: 41481.3359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 25/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8536 - mse: 42731.9297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 26/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3131 - mse: 45248.3633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 27/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3908 - mse: 44800.5156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 28/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8638 - mse: 43646.6719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 29/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6173 - mse: 44382.3633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 30/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2899 - mse: 43801.9375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 31/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1216 - mse: 45172.3008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 32/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.0550 - mse: 44820.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 33/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4728 - mse: 41838.6758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 34/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8403 - mse: 46732.6523 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 35/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5392 - mse: 44185.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 36/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7526 - mse: 44257.8672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 37/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.1063 - mse: 46575.0352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 38/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8698 - mse: 43093.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 39/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.3520 - mse: 47647.3477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 40/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9996 - mse: 45118.8008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 41/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5190 - mse: 43903.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 42/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.1133 - mse: 46199.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 43/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9277 - mse: 45761.1992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 44/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4675 - mse: 42988.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 45/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8126 - mse: 44369.9844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 46/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0888 - mse: 44789.8438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 47/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6252 - mse: 44295.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 48/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4545 - mse: 41307.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 49/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9184 - mse: 43745.7812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 50/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4390 - mse: 44406.6758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 51/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1877 - mse: 44186.3164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 0.0010\n",
      "Epoch 52/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.4594 - mse: 48510.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 53/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2789 - mse: 44560.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 54/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.6483 - mse: 42277.2852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 55/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.0555 - mse: 40673.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 56/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6469 - mse: 42795.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 57/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.2490 - mse: 42648.4883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 58/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3367 - mse: 45655.3789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 59/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5771 - mse: 47147.4453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 60/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3600 - mse: 45206.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 61/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3646 - mse: 43166.7852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 62/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.4261 - mse: 43692.3711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 63/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.3700 - mse: 41553.7812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 64/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0038 - mse: 44185.4336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 65/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9072 - mse: 45989.0312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 66/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.3341 - mse: 47095.7617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 67/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.5228 - mse: 43772.9297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 68/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6714 - mse: 45741.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 69/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0780 - mse: 43611.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 70/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8364 - mse: 44251.4922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 71/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4481 - mse: 46229.4258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 72/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.6581 - mse: 42512.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 73/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8915 - mse: 44185.8516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 74/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2537 - mse: 44072.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 75/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.3723 - mse: 42615.6562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 76/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 103.8319 - mse: 40613.9883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 77/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.3339 - mse: 41164.9219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 78/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3212 - mse: 45414.9258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 79/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6344 - mse: 44337.2188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 80/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3465 - mse: 46393.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 81/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5150 - mse: 46216.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 82/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.6669 - mse: 44851.5547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 83/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1041 - mse: 44760.6914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 84/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4815 - mse: 46973.1758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 85/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6420 - mse: 46709.8789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 86/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9189 - mse: 45556.8008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 87/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6915 - mse: 44013.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 88/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4877 - mse: 45880.0586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 89/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5648 - mse: 44870.0938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 90/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3681 - mse: 45617.6562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 91/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3069 - mse: 43213.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 92/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1101 - mse: 46619.6914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 93/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6162 - mse: 46355.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 94/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0937 - mse: 46253.8203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 95/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.6146 - mse: 47887.4766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 96/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.9963 - mse: 46345.0938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 97/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0144 - mse: 44367.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 98/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9801 - mse: 44516.7227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 99/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2967 - mse: 47016.4062 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 100/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2532 - mse: 46894.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 101/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.9228 - mse: 44436.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.5000e-04\n",
      "Epoch 102/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4717 - mse: 45997.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 103/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0382 - mse: 44570.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 104/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8640 - mse: 46386.5000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 105/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5287 - mse: 43119.2148 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 106/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.8482 - mse: 42767.9414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 107/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9510 - mse: 42414.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 108/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2957 - mse: 45080.8203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 109/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9141 - mse: 43068.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 110/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7133 - mse: 44320.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 111/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.3261 - mse: 43662.0039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 112/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1075 - mse: 44473.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 113/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6403 - mse: 43448.0664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 114/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.6236 - mse: 43497.0625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 115/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5885 - mse: 45137.2812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 116/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6445 - mse: 45762.6641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 117/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3789 - mse: 43707.4570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 118/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2981 - mse: 44347.7852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 119/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8925 - mse: 44855.0352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 120/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3169 - mse: 45270.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 121/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.5733 - mse: 42090.9609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 122/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.7366 - mse: 44717.4453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 123/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5145 - mse: 43854.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 124/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2898 - mse: 41875.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 125/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2255 - mse: 42325.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 126/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3064 - mse: 45618.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 127/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7939 - mse: 43949.1875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 128/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4406 - mse: 45751.0664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 129/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5648 - mse: 45980.0273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 130/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.6355 - mse: 47586.5977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 131/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.4132 - mse: 45981.7461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 132/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3020 - mse: 45155.1875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 133/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.5657 - mse: 44254.7070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 134/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 106.5759 - mse: 42442.1250 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 135/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 109.9659 - mse: 44648.1875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 136/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 106.9464 - mse: 42049.6094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 137/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 107.6749 - mse: 43446.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 138/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.8748 - mse: 44400.3359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 139/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7689 - mse: 43274.5078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 140/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.3550 - mse: 44239.0742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 141/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6316 - mse: 45109.6016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 142/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4861 - mse: 46409.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 143/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.3594 - mse: 47962.3828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 144/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4843 - mse: 43871.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 145/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.3348 - mse: 42190.9766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 146/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2574 - mse: 46090.0625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 147/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3735 - mse: 44243.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 148/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5455 - mse: 41991.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 149/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8578 - mse: 44054.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 150/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2562 - mse: 44495.4492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 151/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5213 - mse: 45466.6836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.2250e-04\n",
      "Epoch 152/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3888 - mse: 44103.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 153/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.0399 - mse: 46181.2500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 154/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.8236 - mse: 45613.2695 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 155/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 114.8844 - mse: 49158.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 156/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.3998 - mse: 44272.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 157/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8303 - mse: 42092.8477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 158/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5208 - mse: 41868.9180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 159/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.1334 - mse: 46295.8438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 160/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.9706 - mse: 45054.0352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 161/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.8752 - mse: 43536.7852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 162/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.8862 - mse: 44283.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 163/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.1564 - mse: 46656.1289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 164/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.8416 - mse: 44772.4375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 165/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.4845 - mse: 44041.6250 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 166/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.9583 - mse: 45755.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 167/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 116.1671 - mse: 48088.3672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 168/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.1711 - mse: 46199.1016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 169/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.6693 - mse: 42787.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 170/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.1476 - mse: 44829.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 171/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.6881 - mse: 45482.2148 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 172/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.2995 - mse: 42115.3359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 173/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.1478 - mse: 41873.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 174/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.6356 - mse: 46330.6055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 175/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.3305 - mse: 44914.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 176/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.0155 - mse: 46100.1367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 177/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.7089 - mse: 44373.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 178/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.6514 - mse: 43628.8320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 179/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.0423 - mse: 47956.7617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 180/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.0351 - mse: 47267.3164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 181/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.6719 - mse: 44962.8516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 182/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.5110 - mse: 41581.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 183/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.0462 - mse: 42662.9492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 184/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.7568 - mse: 44656.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 185/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.0318 - mse: 45472.2266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 186/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.2433 - mse: 42574.8750 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 187/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.8257 - mse: 44871.9531 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 188/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.4089 - mse: 44698.9609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 189/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.5882 - mse: 44851.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 190/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.1047 - mse: 43102.0430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 191/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.3148 - mse: 45854.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 192/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.4264 - mse: 44258.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 193/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.1947 - mse: 41568.7891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 194/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3441 - mse: 45465.6016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 195/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.2403 - mse: 42881.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 196/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.9880 - mse: 44629.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 197/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 114.3831 - mse: 47480.2930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 198/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.4861 - mse: 45070.8438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 199/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 116.3857 - mse: 49550.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 200/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 104.6181 - mse: 40790.6680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 201/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6395 - mse: 45927.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.1413e-04\n",
      "Epoch 202/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.8107 - mse: 47364.4180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 203/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3166 - mse: 44432.5859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 204/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3131 - mse: 44746.8203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 205/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 112.7204 - mse: 47341.0234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 206/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2972 - mse: 46542.2188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 207/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9111 - mse: 42893.8359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 208/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5242 - mse: 44011.4062 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 209/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8634 - mse: 44001.3711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 210/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.0221 - mse: 41878.7422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 211/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6485 - mse: 45738.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 212/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2144 - mse: 42662.0820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 213/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6214 - mse: 42961.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 214/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4564 - mse: 45049.5703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 215/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9876 - mse: 46444.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 216/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4566 - mse: 44976.5430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 217/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3043 - mse: 44175.1211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 218/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4500 - mse: 44353.9375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 219/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.1334 - mse: 44235.4805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 220/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.3889 - mse: 47223.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 221/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3697 - mse: 45159.8555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 222/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.7939 - mse: 47345.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 223/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7220 - mse: 46732.9219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 224/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.7768 - mse: 42184.3867 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 225/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3488 - mse: 46497.6562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 226/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9475 - mse: 47397.9180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 227/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.3706 - mse: 49540.7031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 228/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7550 - mse: 45097.6875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 229/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.7056 - mse: 41830.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 230/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.5063 - mse: 46358.0234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 231/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.9571 - mse: 42881.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 232/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0707 - mse: 44304.4336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 233/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7700 - mse: 45572.3242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 234/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.2707 - mse: 44323.8945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 235/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2758 - mse: 44263.2930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 236/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7643 - mse: 42879.0586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 237/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9426 - mse: 43341.4727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 238/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7348 - mse: 47362.1875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 239/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4645 - mse: 43719.0117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 240/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8672 - mse: 43868.1211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 241/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8513 - mse: 44235.1719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 242/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6154 - mse: 45202.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 243/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2738 - mse: 46284.5117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 244/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0971 - mse: 44595.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 245/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6436 - mse: 46521.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 246/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.8051 - mse: 45597.7539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 247/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2979 - mse: 43307.4961 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 248/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6912 - mse: 45823.9688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 249/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0401 - mse: 47375.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 250/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0867 - mse: 44738.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 251/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4900 - mse: 44418.4727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.2201e-04\n",
      "Epoch 252/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.6645 - mse: 48875.9062 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 253/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3504 - mse: 45447.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 254/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.0299 - mse: 47049.9570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 255/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2531 - mse: 43159.4570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 256/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4156 - mse: 43028.5664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 257/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4777 - mse: 46482.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 258/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5319 - mse: 46835.0000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 259/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5233 - mse: 44420.3320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 260/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6338 - mse: 43365.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 261/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4729 - mse: 46149.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 262/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.5516 - mse: 46225.6875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 263/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8878 - mse: 43646.7891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 264/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7798 - mse: 45569.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 265/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.2017 - mse: 49461.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 266/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9439 - mse: 41993.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 267/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2660 - mse: 42703.9453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 268/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1615 - mse: 44050.3867 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 269/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0979 - mse: 44878.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 270/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4093 - mse: 45833.6016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 271/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3528 - mse: 43631.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 272/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5187 - mse: 44949.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 273/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1954 - mse: 47088.8594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 274/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.0418 - mse: 47712.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 275/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2533 - mse: 47261.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 276/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4847 - mse: 45633.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 277/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6111 - mse: 43669.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 278/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.0259 - mse: 44898.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 279/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.7530 - mse: 47915.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 280/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0253 - mse: 46962.6680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 281/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0017 - mse: 43795.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 282/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7238 - mse: 45359.8203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 283/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 114.0590 - mse: 47319.6016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 284/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8612 - mse: 43931.6875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 285/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2528 - mse: 42825.3086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 286/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7129 - mse: 41952.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 287/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6673 - mse: 43080.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 288/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.8164 - mse: 41609.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 289/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8250 - mse: 43124.4336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 290/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4875 - mse: 44866.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 291/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6842 - mse: 46323.1289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 292/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6490 - mse: 42763.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 293/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2210 - mse: 47227.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 294/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.6308 - mse: 41994.2188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 295/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9181 - mse: 44645.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 296/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5696 - mse: 43023.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 297/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9687 - mse: 45234.6680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 298/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6674 - mse: 46373.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 299/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7171 - mse: 42568.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 300/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9397 - mse: 43106.3516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 301/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2208 - mse: 44047.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.4371e-04\n",
      "Epoch 302/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3372 - mse: 42739.0469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 303/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 111.0115 - mse: 44557.3984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 304/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.3954 - mse: 47591.8242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 305/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6722 - mse: 44436.7539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 306/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2874 - mse: 42725.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 307/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7013 - mse: 43985.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 308/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9814 - mse: 46642.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 309/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7989 - mse: 44022.2383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 310/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4860 - mse: 44751.0820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 311/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0465 - mse: 44867.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 312/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7601 - mse: 44581.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 313/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.1278 - mse: 47212.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 314/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.3267 - mse: 46785.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 315/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9594 - mse: 46591.5977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 316/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2872 - mse: 43737.4219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 317/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5443 - mse: 42133.1602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 318/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4482 - mse: 45181.9062 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 319/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6518 - mse: 45224.3750 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 320/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.4093 - mse: 46267.7031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 321/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5702 - mse: 47194.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 322/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 115.0153 - mse: 48005.7930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 323/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9848 - mse: 45436.7930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 324/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 105.4422 - mse: 40965.6211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 325/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4336 - mse: 43273.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 326/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3488 - mse: 44208.7852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 327/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.7791 - mse: 41733.7539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 328/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5138 - mse: 46071.4805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 329/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.0302 - mse: 41599.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 330/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.0950 - mse: 42962.9844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 331/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7952 - mse: 44025.9180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 332/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1201 - mse: 44456.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 333/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - loss: 108.5508 - mse: 43686.1367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 334/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 110.1604 - mse: 44477.2734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 335/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9949 - mse: 44120.4609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 336/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.1813 - mse: 44412.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 337/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3091 - mse: 42336.2109 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 338/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4478 - mse: 43635.0938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 339/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8324 - mse: 42896.4766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 340/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4908 - mse: 42199.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 341/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.9273 - mse: 42708.3086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 342/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6576 - mse: 45801.2500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 343/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.1079 - mse: 42288.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 344/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4054 - mse: 44906.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 345/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4119 - mse: 44494.3750 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 346/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4332 - mse: 44515.7930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 347/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - loss: 109.9248 - mse: 45153.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 348/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.8567 - mse: 43994.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 349/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9787 - mse: 45453.1719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 350/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1819 - mse: 43949.2617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 351/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.7511 - mse: 46669.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.7715e-04\n",
      "Epoch 352/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4347 - mse: 45475.4180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 353/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3157 - mse: 43140.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 354/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.7741 - mse: 42648.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 355/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0857 - mse: 42318.3320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 356/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5358 - mse: 43547.4453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 357/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3765 - mse: 44130.9023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 358/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0624 - mse: 45041.8320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 359/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0901 - mse: 44169.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 360/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3561 - mse: 45720.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 361/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6804 - mse: 45925.9180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 362/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2719 - mse: 42729.5312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 363/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9691 - mse: 43349.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 364/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2232 - mse: 43973.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 365/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0651 - mse: 46113.2539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 366/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2081 - mse: 45310.9727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 367/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6183 - mse: 45629.4570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 368/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8712 - mse: 46182.3477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 369/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5971 - mse: 42787.3984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 370/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1875 - mse: 44748.1719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 371/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3369 - mse: 46069.8281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 372/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1759 - mse: 44016.9883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 373/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5708 - mse: 42877.5312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 374/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.8982 - mse: 46856.7734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 375/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7642 - mse: 44722.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 376/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4236 - mse: 42629.5078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 377/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.0476 - mse: 41197.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 378/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1987 - mse: 44431.3867 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 379/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.5522 - mse: 45949.4766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 380/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.9158 - mse: 42927.4766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 381/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1777 - mse: 44679.5859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 382/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.2582 - mse: 47703.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 383/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9887 - mse: 46060.5000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 384/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.5691 - mse: 45201.8633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 385/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6240 - mse: 44543.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 386/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4193 - mse: 42073.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 387/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3633 - mse: 46326.0117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 388/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3991 - mse: 45759.6367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 389/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0614 - mse: 45028.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 390/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4327 - mse: 42992.5859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 391/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3122 - mse: 43298.0703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 392/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1673 - mse: 45388.3789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 393/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.1572 - mse: 46946.4531 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 394/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2638 - mse: 43936.2852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 395/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5503 - mse: 43385.9297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 396/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1446 - mse: 42003.5742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 397/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1361 - mse: 47190.9922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 398/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1657 - mse: 42946.2734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 399/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5144 - mse: 46122.3008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 400/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.4363 - mse: 47255.6641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 401/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.4715 - mse: 48238.3672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2058e-04\n",
      "Epoch 402/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9016 - mse: 46181.5352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 403/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4773 - mse: 43141.0391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 404/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.7814 - mse: 44942.2461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 405/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0397 - mse: 44754.5078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 406/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2194 - mse: 43521.7070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 407/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3131 - mse: 43742.9023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 408/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4380 - mse: 45534.4805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 409/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9816 - mse: 44486.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 410/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.5842 - mse: 45477.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 411/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4957 - mse: 43730.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 412/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3110 - mse: 43565.8828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 413/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.7812 - mse: 42140.4180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 414/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1038 - mse: 42507.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 415/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7737 - mse: 44936.5977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 416/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.0458 - mse: 42257.1719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 417/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4304 - mse: 46068.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 418/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.0056 - mse: 45452.1680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 419/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6228 - mse: 43298.7617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 420/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.4386 - mse: 48140.6094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 421/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8293 - mse: 45434.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 422/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5587 - mse: 44663.2461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 423/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.3750 - mse: 46708.8516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 424/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0220 - mse: 44028.5156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 425/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5498 - mse: 45309.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 426/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.3842 - mse: 46680.0430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 427/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.9042 - mse: 41814.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 428/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.7145 - mse: 46533.4609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 429/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3128 - mse: 45143.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 430/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8095 - mse: 46095.9688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 431/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4956 - mse: 45118.5391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 432/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7580 - mse: 44577.3242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 433/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6149 - mse: 45500.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 434/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1012 - mse: 44500.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 435/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5545 - mse: 46912.1914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 436/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.7164 - mse: 43061.6250 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 437/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9450 - mse: 45594.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 438/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2823 - mse: 40765.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 439/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.9157 - mse: 44466.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 440/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6490 - mse: 45300.8594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 441/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4463 - mse: 41655.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 442/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6097 - mse: 43356.8672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 443/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4374 - mse: 46855.4766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 444/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.0201 - mse: 44267.5859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 445/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.7052 - mse: 41802.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 446/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9227 - mse: 45110.1758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 447/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4789 - mse: 45445.3789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 448/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4434 - mse: 46775.8359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 449/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1335 - mse: 42457.9844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 450/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.0020 - mse: 44351.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 451/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.5753 - mse: 42378.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.7249e-04\n",
      "Epoch 452/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3001 - mse: 42279.9141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 453/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.7039 - mse: 47943.3086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 454/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1287 - mse: 44818.1562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 455/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0376 - mse: 48467.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 456/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6296 - mse: 44195.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 457/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3079 - mse: 45479.5312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 458/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4942 - mse: 42950.8203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 459/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6418 - mse: 44228.4492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 460/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7441 - mse: 44508.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 461/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.4016 - mse: 40452.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 462/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8667 - mse: 46063.0703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 463/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7924 - mse: 43622.8008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 464/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8660 - mse: 43648.7070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 465/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9910 - mse: 44640.1016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 466/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9846 - mse: 45137.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 467/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.9106 - mse: 48224.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 468/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8061 - mse: 44124.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 469/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7820 - mse: 46333.4961 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 470/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6193 - mse: 43525.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 471/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0594 - mse: 44811.4141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 472/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8427 - mse: 43499.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 473/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0925 - mse: 43507.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 474/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1721 - mse: 42896.5312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 475/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7118 - mse: 43811.7500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 476/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7121 - mse: 43482.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 477/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.4965 - mse: 42106.3828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 478/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9156 - mse: 45480.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 479/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7618 - mse: 44362.7070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 480/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1175 - mse: 42012.2461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 481/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6427 - mse: 45578.1758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 482/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.2720 - mse: 44236.8320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 483/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6514 - mse: 46327.5625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 484/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5789 - mse: 44649.1562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 485/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7161 - mse: 43748.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 486/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8178 - mse: 44441.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 487/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.4604 - mse: 45004.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 488/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.8158 - mse: 47214.3242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 489/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.8107 - mse: 42495.5391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 490/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4769 - mse: 46071.3281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 491/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3645 - mse: 42708.1172 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 492/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.5153 - mse: 47973.0039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 493/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7161 - mse: 42775.8789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 494/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.1534 - mse: 48678.9258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 495/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1871 - mse: 41806.0664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 496/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 117.7924 - mse: 50469.0742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 497/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1318 - mse: 46684.9258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 498/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2914 - mse: 46551.2773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 499/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3311 - mse: 44122.3984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 500/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1483 - mse: 45438.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 501/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7519 - mse: 45644.1875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3162e-04\n",
      "Epoch 502/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3208 - mse: 45169.9297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 503/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5142 - mse: 44860.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 504/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9441 - mse: 47073.3242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 505/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4191 - mse: 45157.2930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 506/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6598 - mse: 44777.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 507/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.4669 - mse: 45664.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 508/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7868 - mse: 44227.0820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 509/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8729 - mse: 44678.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 510/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7356 - mse: 44509.0703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 511/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0903 - mse: 43258.0859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 512/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 109.4703 - mse: 45121.2461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 513/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.2635 - mse: 40793.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 514/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6055 - mse: 43387.5703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 515/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8822 - mse: 45807.1602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 516/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7586 - mse: 44626.7773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 517/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.7144 - mse: 42653.5781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 518/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4800 - mse: 44257.6328 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 519/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6918 - mse: 45717.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 520/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5311 - mse: 42720.6836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 521/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8602 - mse: 44646.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 522/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3474 - mse: 45700.9844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 523/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2625 - mse: 45604.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 524/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.8539 - mse: 43142.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 525/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7357 - mse: 43711.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 526/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.9973 - mse: 41594.0859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 527/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.0596 - mse: 40789.9570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 528/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3713 - mse: 43585.6680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 529/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.3758 - mse: 43272.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 530/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3962 - mse: 42244.9609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 531/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8414 - mse: 45257.0703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 532/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0380 - mse: 46048.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 533/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1330 - mse: 44643.0859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 534/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1347 - mse: 43426.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 535/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5997 - mse: 42834.8086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 536/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2648 - mse: 45512.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 537/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6989 - mse: 44132.5156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 538/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4809 - mse: 44451.1523 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 539/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.0013 - mse: 43951.2812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 540/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8725 - mse: 45459.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 541/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3235 - mse: 43990.0742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 542/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.0776 - mse: 47757.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 543/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8751 - mse: 43267.1289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 544/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7810 - mse: 43530.7227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 545/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9339 - mse: 44322.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 546/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.5443 - mse: 41467.1172 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 547/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5634 - mse: 41423.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 548/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.5001 - mse: 48004.8320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 549/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.8337 - mse: 48013.3359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 550/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3281 - mse: 46157.2539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 551/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5916 - mse: 45346.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.9687e-04\n",
      "Epoch 552/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.1500 - mse: 48107.8945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 553/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2980 - mse: 44662.8242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 554/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8878 - mse: 45589.1680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 555/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1271 - mse: 47435.6328 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 556/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4667 - mse: 44379.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 557/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9293 - mse: 47689.2891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 558/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2594 - mse: 47070.2500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 559/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1775 - mse: 42640.4414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 560/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.9229 - mse: 43374.2812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 561/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6660 - mse: 45667.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 562/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6431 - mse: 47054.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 563/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2185 - mse: 42857.0430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 564/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 104.6338 - mse: 41153.5781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 565/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2338 - mse: 46045.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 566/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.6870 - mse: 40974.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 567/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3392 - mse: 46270.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 568/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5425 - mse: 42619.1953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 569/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8234 - mse: 44777.4492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 570/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6666 - mse: 44619.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 571/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8544 - mse: 45024.9531 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 572/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.8581 - mse: 44564.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 573/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3226 - mse: 43321.8320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 574/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.1364 - mse: 48426.8281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 575/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.4725 - mse: 45377.5000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 576/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1578 - mse: 42551.6914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 577/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7502 - mse: 45296.0820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 578/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4116 - mse: 42892.8008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 579/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0769 - mse: 44487.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 580/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5913 - mse: 44946.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 581/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3471 - mse: 43835.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 582/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 104.6663 - mse: 40819.7734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 583/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3977 - mse: 42725.1016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 584/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8551 - mse: 43681.5391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 585/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 114.3645 - mse: 47578.8750 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 586/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2423 - mse: 43799.6016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 587/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3055 - mse: 44110.0625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 588/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1547 - mse: 44515.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 589/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7742 - mse: 45741.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 590/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2973 - mse: 42126.8281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 591/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.7443 - mse: 47144.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 592/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.9790 - mse: 47609.9766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 593/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7979 - mse: 44869.8320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 594/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4128 - mse: 43164.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 595/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1714 - mse: 45754.0039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 596/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.2337 - mse: 44523.2422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 597/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4648 - mse: 46127.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 598/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3262 - mse: 44883.2422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 599/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4246 - mse: 44985.0234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 600/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2678 - mse: 45909.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 601/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0157 - mse: 45448.0391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.6734e-04\n",
      "Epoch 602/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4859 - mse: 43180.0391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 603/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0247 - mse: 43144.2305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 604/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2598 - mse: 43710.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 605/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3846 - mse: 45285.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 606/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0509 - mse: 43539.0430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 607/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0933 - mse: 44604.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 608/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.2480 - mse: 48261.7461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 609/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7733 - mse: 44330.9727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 610/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0067 - mse: 43113.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 611/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.9113 - mse: 41143.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 612/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6951 - mse: 44182.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 613/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.5430 - mse: 46893.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 614/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.1977 - mse: 43361.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 615/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4661 - mse: 44834.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 616/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7755 - mse: 43295.0078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 617/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4127 - mse: 41567.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 618/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1722 - mse: 46125.9766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 619/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5521 - mse: 42151.6328 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 620/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.3751 - mse: 49216.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 621/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2725 - mse: 42338.6836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 622/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.1096 - mse: 45328.3008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 623/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.6283 - mse: 42743.0352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 624/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2514 - mse: 45526.7148 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 625/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1935 - mse: 42432.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 626/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5165 - mse: 44325.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 627/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.8936 - mse: 47640.6719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 628/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.6493 - mse: 48044.0625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 629/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.9463 - mse: 42728.6211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 630/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4229 - mse: 43148.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 631/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7405 - mse: 46602.6562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 632/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9180 - mse: 46156.8594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 633/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8499 - mse: 45677.0234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 634/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9317 - mse: 43928.5547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 635/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2661 - mse: 43835.5156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 636/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.4859 - mse: 44876.6641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 637/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 117.3045 - mse: 48775.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 638/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1854 - mse: 45126.0508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 639/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7331 - mse: 45255.7891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 640/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1307 - mse: 47423.0430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 641/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.5003 - mse: 46855.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 642/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5805 - mse: 42688.1953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 643/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4725 - mse: 46825.9492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 644/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3813 - mse: 44562.2031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 645/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4796 - mse: 43953.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 646/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.2417 - mse: 46289.7773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 647/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2467 - mse: 43179.1211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 648/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8504 - mse: 44598.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 649/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8839 - mse: 44515.7148 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 650/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6540 - mse: 43778.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 651/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.2229 - mse: 44922.2852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.4224e-04\n",
      "Epoch 652/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1870 - mse: 44267.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 653/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7578 - mse: 43600.1562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 654/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2284 - mse: 45132.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 655/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9330 - mse: 44713.9414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 656/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1587 - mse: 43773.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 657/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5202 - mse: 44421.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 658/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6471 - mse: 43387.0273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 659/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1289 - mse: 44675.2734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 660/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2536 - mse: 46554.2930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 661/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2639 - mse: 44889.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 662/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3756 - mse: 44531.4844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 663/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1723 - mse: 41516.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 664/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0405 - mse: 45050.1602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 665/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9989 - mse: 45307.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 666/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4023 - mse: 43375.9141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 667/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7521 - mse: 44439.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 668/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5286 - mse: 43877.8633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 669/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8672 - mse: 43083.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 670/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2245 - mse: 46247.3828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 671/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4809 - mse: 46326.7812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 672/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8777 - mse: 43262.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 673/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5642 - mse: 46270.8047 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 674/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4514 - mse: 41587.7539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 675/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1404 - mse: 43841.9180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 676/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.2192 - mse: 43508.0078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 677/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.0621 - mse: 48788.4453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 678/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0540 - mse: 44252.2812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 679/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5726 - mse: 46014.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 680/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 109.7080 - mse: 44077.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 681/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3509 - mse: 47025.4180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 682/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3411 - mse: 44651.6406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 683/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2219 - mse: 45576.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 684/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2548 - mse: 42698.5664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 685/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.1237 - mse: 43728.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 686/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1550 - mse: 44260.4375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 687/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9402 - mse: 45001.2305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 688/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4054 - mse: 44777.5898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 689/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2945 - mse: 46764.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 690/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8376 - mse: 45291.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 691/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7597 - mse: 44647.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 692/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.3171 - mse: 46727.9883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 693/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.3853 - mse: 50160.4805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 694/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 103.6650 - mse: 40046.9961 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 695/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3581 - mse: 43037.9062 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 696/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.9498 - mse: 46975.5742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 697/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0125 - mse: 44731.9688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 698/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6958 - mse: 44424.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 699/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 104.8849 - mse: 41165.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 700/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7197 - mse: 46579.3516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 701/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6988 - mse: 42444.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.2091e-04\n",
      "Epoch 702/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.3438 - mse: 42892.4219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 703/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.7822 - mse: 46080.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 704/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5446 - mse: 43438.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 705/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2064 - mse: 41762.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 706/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.5535 - mse: 47021.5742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 707/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.2838 - mse: 47935.6094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 708/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0522 - mse: 45325.6797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 709/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.4606 - mse: 48238.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 710/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 104.8864 - mse: 41263.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 711/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5260 - mse: 44457.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 712/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0054 - mse: 45188.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 713/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2474 - mse: 45349.5820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 714/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8867 - mse: 43392.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 715/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.4101 - mse: 47167.2383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 716/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0011 - mse: 45070.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 717/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.7728 - mse: 47859.5000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 718/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.0111 - mse: 41980.9492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 719/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5840 - mse: 45905.7734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 720/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3677 - mse: 43536.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 721/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.8979 - mse: 47367.3789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 722/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.6247 - mse: 48356.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 723/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6184 - mse: 44381.3516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 724/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3925 - mse: 45599.6875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 725/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1925 - mse: 44374.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 726/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4025 - mse: 43656.9023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 727/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6483 - mse: 46194.2695 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 728/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9408 - mse: 44576.2344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 729/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.9951 - mse: 40875.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 730/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9478 - mse: 44581.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 731/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8844 - mse: 48202.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 732/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.1608 - mse: 48393.0938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 733/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7086 - mse: 43408.7031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 734/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6053 - mse: 44405.4375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 735/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5334 - mse: 44023.0820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 736/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.7409 - mse: 43050.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 737/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1027 - mse: 44077.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 738/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7751 - mse: 44482.1367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 739/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.0919 - mse: 42954.7422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 740/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2855 - mse: 46278.4961 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 741/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.5532 - mse: 40741.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 742/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9480 - mse: 44713.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 743/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8542 - mse: 45187.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 744/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.1703 - mse: 41268.4922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 745/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.7490 - mse: 45454.5625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 746/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7577 - mse: 44235.1133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 747/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.4829 - mse: 41760.4609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 748/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1953 - mse: 44414.5430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 749/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6485 - mse: 44349.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 750/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.2897 - mse: 43923.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 751/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9785 - mse: 43373.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.0277e-04\n",
      "Epoch 752/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2637 - mse: 44583.5977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 753/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6380 - mse: 45910.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 754/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7594 - mse: 42693.4414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 755/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.1163 - mse: 44695.4492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 756/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9495 - mse: 45330.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 757/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9187 - mse: 42723.7773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 758/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2259 - mse: 44422.4570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 759/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3285 - mse: 44725.7539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 760/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5283 - mse: 41547.1289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 761/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1016 - mse: 44784.6523 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 762/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.6664 - mse: 43000.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 763/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3796 - mse: 45578.8945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 764/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5849 - mse: 43890.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 765/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3080 - mse: 45363.6055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 766/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0212 - mse: 44927.3828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 767/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 116.8607 - mse: 49037.6719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 768/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7223 - mse: 42738.9375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 769/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9146 - mse: 45419.1992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 770/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2108 - mse: 46025.4414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 771/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9371 - mse: 45325.7969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 772/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0249 - mse: 43651.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 773/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8527 - mse: 43859.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 774/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4623 - mse: 42790.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 775/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.6069 - mse: 40949.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 776/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5963 - mse: 44903.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 777/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3990 - mse: 46619.4414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 778/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8763 - mse: 43439.6016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 779/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.6610 - mse: 46538.8477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 780/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9482 - mse: 45442.0469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 781/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.8964 - mse: 41794.9219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 782/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.9659 - mse: 44717.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 783/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2342 - mse: 42750.6719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 784/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0511 - mse: 43328.0820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 785/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4925 - mse: 44513.7109 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 786/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7355 - mse: 45433.9922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 787/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.2617 - mse: 43881.7500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 788/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1974 - mse: 45332.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 789/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0839 - mse: 44645.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 790/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4337 - mse: 44810.8672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 791/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4937 - mse: 42447.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 792/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6666 - mse: 43823.0664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 793/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2469 - mse: 44535.7695 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 794/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8992 - mse: 43426.0000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 795/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8727 - mse: 43507.9883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 796/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8431 - mse: 44378.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 797/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.4922 - mse: 41940.9414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 798/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6382 - mse: 46786.6719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 799/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8027 - mse: 44285.2734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 800/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6775 - mse: 42486.6914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 801/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8732 - mse: 44376.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 8.7354e-05\n",
      "Epoch 802/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.1427 - mse: 47910.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 803/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0506 - mse: 45919.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 804/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.5138 - mse: 45372.5430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 805/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5854 - mse: 45135.7539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 806/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4499 - mse: 45032.8555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 807/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5281 - mse: 45593.2188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 808/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6618 - mse: 43288.1523 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 809/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.0449 - mse: 43603.5000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 810/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.0985 - mse: 47752.0000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 811/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3288 - mse: 45299.3516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 812/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7372 - mse: 45075.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 813/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.0016 - mse: 47311.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 814/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.5316 - mse: 42880.7227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 815/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5772 - mse: 46173.2031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 816/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4373 - mse: 44965.2617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 817/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7787 - mse: 44602.9453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 818/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1129 - mse: 43489.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 819/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1967 - mse: 43230.3008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 820/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5702 - mse: 45025.9375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 821/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1010 - mse: 43252.5781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 822/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.4068 - mse: 45967.6367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 823/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2086 - mse: 42904.5430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 824/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.4315 - mse: 46558.3086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 825/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1591 - mse: 44867.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 826/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7532 - mse: 43178.4922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 827/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.4904 - mse: 44498.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 828/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3992 - mse: 43989.6875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 829/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.8682 - mse: 44341.2852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 830/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6042 - mse: 43925.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 831/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6920 - mse: 45797.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 832/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5083 - mse: 42499.6055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 833/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.1529 - mse: 47333.9219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 834/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3240 - mse: 42281.6211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 835/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.8529 - mse: 48983.1562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 836/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.0711 - mse: 42908.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 837/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6121 - mse: 44243.5703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 838/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 105.2807 - mse: 42049.7070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 839/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8955 - mse: 45167.2773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 840/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3455 - mse: 46297.8672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 841/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.7346 - mse: 43079.5625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 842/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1655 - mse: 43961.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 843/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.6214 - mse: 47615.7891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 844/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6025 - mse: 44288.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 845/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.6727 - mse: 48334.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 846/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2122 - mse: 46436.5352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 847/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8652 - mse: 45673.4922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 848/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.6762 - mse: 44511.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 849/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3857 - mse: 44376.2070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 850/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.8077 - mse: 40669.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 851/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.8173 - mse: 47766.1211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 7.4251e-05\n",
      "Epoch 852/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0609 - mse: 43723.7773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 853/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2500 - mse: 45564.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 854/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6475 - mse: 43808.2773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 855/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6806 - mse: 46406.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 856/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1056 - mse: 41764.2070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 857/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.7238 - mse: 42386.6328 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 858/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.8761 - mse: 43564.1172 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 859/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.1432 - mse: 46109.6836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 860/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4005 - mse: 43652.0078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 861/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1742 - mse: 44907.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 862/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8834 - mse: 46938.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 863/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5821 - mse: 42514.5820 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 864/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5077 - mse: 41556.1680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 865/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3093 - mse: 44930.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 866/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2357 - mse: 43157.3984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 867/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6395 - mse: 42773.1211 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 868/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4556 - mse: 43263.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 869/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2845 - mse: 44548.9609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 870/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1393 - mse: 44250.6250 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 871/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2867 - mse: 45630.5664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 872/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3704 - mse: 42852.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 873/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.8016 - mse: 43875.1992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 874/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7411 - mse: 43011.3281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 875/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1724 - mse: 45096.4258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 876/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9590 - mse: 43449.0078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 877/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.9274 - mse: 46437.8633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 878/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3254 - mse: 44354.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 879/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.5416 - mse: 46007.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 880/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9708 - mse: 47690.6562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 881/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 102.0649 - mse: 39461.9648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 882/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5650 - mse: 42445.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 883/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2988 - mse: 43943.9688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 884/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7187 - mse: 45184.8359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 885/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4418 - mse: 44207.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 886/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7049 - mse: 43889.8242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 887/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 105.7469 - mse: 42117.8594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 888/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2909 - mse: 41614.7773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 889/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9504 - mse: 42907.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 890/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8566 - mse: 44929.4414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 891/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2109 - mse: 44625.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 892/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9259 - mse: 43762.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 893/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1256 - mse: 44178.5898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 894/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9804 - mse: 45270.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 895/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8033 - mse: 44587.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 896/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7635 - mse: 44264.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 897/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9908 - mse: 46403.1719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 898/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8776 - mse: 44783.5703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 899/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3112 - mse: 43878.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 900/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4871 - mse: 43717.9531 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 901/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5216 - mse: 44414.3320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 6.3113e-05\n",
      "Epoch 902/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9716 - mse: 46046.3984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 903/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5826 - mse: 45070.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 904/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4478 - mse: 45541.5781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 905/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.7433 - mse: 46632.7656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 906/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9011 - mse: 44712.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 907/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 119.2383 - mse: 51012.1758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 908/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.0636 - mse: 44061.7500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 909/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.6427 - mse: 45821.9648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 910/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.3299 - mse: 47828.9258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 911/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.8904 - mse: 42293.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 912/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2112 - mse: 45498.0742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 913/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2292 - mse: 43814.7812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 914/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9764 - mse: 44968.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 915/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4324 - mse: 45697.7773 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 916/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0098 - mse: 44247.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 917/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8700 - mse: 44365.5312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 918/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4132 - mse: 44883.5000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 919/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.5383 - mse: 41588.4570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 920/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7267 - mse: 44605.0078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 921/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1595 - mse: 44647.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 922/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8239 - mse: 43484.1172 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 923/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4218 - mse: 43786.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 924/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1296 - mse: 43249.7930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 925/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3523 - mse: 45057.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 926/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3743 - mse: 44941.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 927/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.7312 - mse: 42029.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 928/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3242 - mse: 43816.3828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 929/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6618 - mse: 45251.9102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 930/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5968 - mse: 45461.1289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 931/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3103 - mse: 42970.5859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 932/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.9323 - mse: 43595.4180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 933/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5937 - mse: 42623.4062 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 934/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.8613 - mse: 48342.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 935/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4088 - mse: 44525.9727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 936/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5940 - mse: 45309.8438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 937/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 104.9265 - mse: 40482.0117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 938/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1055 - mse: 44212.4531 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 939/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3262 - mse: 44026.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 940/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5730 - mse: 44362.1992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 941/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4358 - mse: 45014.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 942/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9609 - mse: 45241.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 943/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1266 - mse: 43704.0312 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 944/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4530 - mse: 45822.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 945/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6377 - mse: 42193.8047 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 946/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3445 - mse: 45684.2422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 947/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2007 - mse: 46013.6914 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 948/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.7676 - mse: 41906.4883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 949/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8178 - mse: 45070.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 950/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4971 - mse: 44743.3789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 951/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4856 - mse: 43783.7734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 5.3646e-05\n",
      "Epoch 952/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6503 - mse: 43527.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 953/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.5388 - mse: 43896.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 954/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4051 - mse: 46673.6055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 955/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4101 - mse: 45908.5273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 956/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8689 - mse: 47490.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 957/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.3826 - mse: 48683.7070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 958/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.6497 - mse: 45839.0859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 959/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2941 - mse: 44022.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 960/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9347 - mse: 46238.1875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 961/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7365 - mse: 44784.2305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 962/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.7090 - mse: 47665.4727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 963/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.5178 - mse: 48514.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 964/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1515 - mse: 42199.0117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 965/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5640 - mse: 43454.6836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 966/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9498 - mse: 44978.3008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 967/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4076 - mse: 43311.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 968/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.1181 - mse: 47887.5859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 969/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.6738 - mse: 48482.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 970/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2491 - mse: 42418.0664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 971/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0102 - mse: 42508.8828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 972/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9445 - mse: 43820.4180 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 973/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5908 - mse: 44321.5078 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 974/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4610 - mse: 46442.4727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 975/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7319 - mse: 46616.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 976/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.0144 - mse: 48769.3984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 977/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4986 - mse: 46491.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 978/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5660 - mse: 44443.7227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 979/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4071 - mse: 45453.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 980/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7620 - mse: 45180.5234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 981/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5649 - mse: 44733.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 982/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.3947 - mse: 42168.3555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 983/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3320 - mse: 42899.9844 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 984/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0281 - mse: 43107.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 985/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7257 - mse: 46024.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 986/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.0099 - mse: 44712.9648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 987/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7808 - mse: 42460.8594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 988/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4951 - mse: 45434.4453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 989/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.0934 - mse: 48329.9141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 990/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0024 - mse: 44148.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 991/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 105.2980 - mse: 41409.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 992/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5711 - mse: 45765.3320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 993/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.0102 - mse: 45639.5117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 994/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5274 - mse: 45205.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 995/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.1919 - mse: 46546.2539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 996/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7113 - mse: 45653.9297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 997/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.6157 - mse: 47777.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 998/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 105.6670 - mse: 41489.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 999/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2535 - mse: 44528.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 1000/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2442 - mse: 45182.6172 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 1001/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9884 - mse: 45109.3594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 4.5599e-05\n",
      "Epoch 1002/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7445 - mse: 43996.0352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1003/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 113.2207 - mse: 45821.6992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1004/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9300 - mse: 42268.5352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1005/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 108.4025 - mse: 43227.9453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1006/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3581 - mse: 43975.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1007/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.3628 - mse: 47047.7188 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1008/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1776 - mse: 42939.3086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1009/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6408 - mse: 42937.8047 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1010/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7387 - mse: 43890.1680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1011/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5340 - mse: 43820.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1012/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9281 - mse: 45622.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1013/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9208 - mse: 45110.1992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1014/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6661 - mse: 46855.8867 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1015/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4960 - mse: 40932.0234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1016/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7649 - mse: 46023.8555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1017/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4574 - mse: 43433.8984 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1018/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7715 - mse: 45240.7852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1019/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.4683 - mse: 41710.6367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1020/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4462 - mse: 45570.3320 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1021/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1786 - mse: 44785.7461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1022/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2764 - mse: 44948.6992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1023/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9208 - mse: 42920.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1024/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7238 - mse: 45562.2227 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1025/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2769 - mse: 46416.7500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1026/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4235 - mse: 43323.8242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1027/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2120 - mse: 43843.1719 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1028/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1811 - mse: 44977.4883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1029/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4955 - mse: 42982.4883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1030/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8044 - mse: 43750.8516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1031/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0804 - mse: 44607.4141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1032/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2414 - mse: 44935.2266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1033/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3085 - mse: 45588.9883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1034/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8950 - mse: 44319.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1035/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.1630 - mse: 42678.9570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1036/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6622 - mse: 44692.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1037/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9109 - mse: 43241.9375 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1038/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.6870 - mse: 41399.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1039/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2091 - mse: 44757.3047 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1040/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0619 - mse: 44484.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1041/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4676 - mse: 44702.6680 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1042/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4798 - mse: 44259.6367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1043/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.3392 - mse: 47322.4219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1044/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2067 - mse: 46329.9648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1045/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4325 - mse: 43946.8008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1046/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9187 - mse: 43717.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1047/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 104.6275 - mse: 40809.3633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1048/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.3294 - mse: 41665.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1049/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.2814 - mse: 42306.9688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1050/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5325 - mse: 44784.4922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1051/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7220 - mse: 42894.3477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.8760e-05\n",
      "Epoch 1052/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 112.5407 - mse: 46330.4297 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1053/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0827 - mse: 43863.0273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1054/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9468 - mse: 46238.8789 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1055/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9125 - mse: 46831.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1056/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9246 - mse: 44343.5742 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1057/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7989 - mse: 46188.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1058/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0243 - mse: 43748.6250 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1059/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.4248 - mse: 41446.2422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1060/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7695 - mse: 44060.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1061/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3320 - mse: 42440.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1062/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9249 - mse: 44372.5977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1063/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.0541 - mse: 47839.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1064/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5372 - mse: 44185.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1065/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1117 - mse: 46152.1484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1066/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5050 - mse: 43397.6641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1067/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0437 - mse: 43941.0547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1068/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7486 - mse: 41445.2891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1069/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2374 - mse: 43444.3672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1070/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4310 - mse: 45155.4258 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1071/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2276 - mse: 45073.0430 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1072/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3934 - mse: 43503.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1073/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9938 - mse: 45103.2852 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1074/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.5375 - mse: 43681.4219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1075/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.9644 - mse: 43767.2344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1076/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.5710 - mse: 47325.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1077/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7433 - mse: 46364.4492 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1078/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.5219 - mse: 41336.7344 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1079/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3658 - mse: 42730.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1080/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8913 - mse: 43207.3164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1081/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6920 - mse: 41030.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1082/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5393 - mse: 44814.0391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1083/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6928 - mse: 43394.8086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1084/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.0530 - mse: 46093.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1085/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9125 - mse: 45853.7656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1086/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.0319 - mse: 46740.8828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1087/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.6511 - mse: 43396.0859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1088/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5831 - mse: 44312.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1089/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5946 - mse: 45571.8828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1090/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.6282 - mse: 46643.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1091/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9006 - mse: 43769.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1092/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3209 - mse: 43219.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1093/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8235 - mse: 45245.4883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1094/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4467 - mse: 42855.6406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1095/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.7540 - mse: 44412.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1096/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2497 - mse: 46809.9453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1097/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1351 - mse: 46688.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1098/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.8685 - mse: 47062.9570 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1099/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4717 - mse: 42021.3008 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1100/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7897 - mse: 45853.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1101/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0636 - mse: 44278.9648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 3.2946e-05\n",
      "Epoch 1102/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.6148 - mse: 45926.8711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1103/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8529 - mse: 44409.5469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1104/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2656 - mse: 45427.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1105/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.4791 - mse: 47893.7031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1106/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9170 - mse: 44442.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1107/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3398 - mse: 45548.8633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1108/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5831 - mse: 44797.5352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1109/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9395 - mse: 45230.8672 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1110/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6331 - mse: 46061.1094 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1111/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3356 - mse: 45896.1836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1112/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7964 - mse: 44704.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1113/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2633 - mse: 46302.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1114/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.7332 - mse: 42425.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1115/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5624 - mse: 42975.3086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1116/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7248 - mse: 42219.9727 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1117/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0166 - mse: 42819.3594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1118/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8162 - mse: 42560.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1119/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5136 - mse: 43475.9141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1120/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7752 - mse: 46169.6367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1121/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1935 - mse: 44353.9453 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1122/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.5977 - mse: 46441.4766 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1123/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1104 - mse: 43608.6875 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1124/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3002 - mse: 42226.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1125/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.2557 - mse: 47228.5391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1126/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1169 - mse: 44159.2070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1127/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8659 - mse: 44694.4961 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1128/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8438 - mse: 43041.5195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1129/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5759 - mse: 44576.2539 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1130/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8817 - mse: 43582.5039 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1131/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.3531 - mse: 47071.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1132/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.9978 - mse: 44672.8438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1133/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.7467 - mse: 40972.5664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1134/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.9148 - mse: 48121.2266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1135/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2193 - mse: 42900.7383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1136/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3283 - mse: 46391.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1137/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3671 - mse: 44430.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1138/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5376 - mse: 44069.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1139/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 116.2573 - mse: 49587.6758 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1140/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3323 - mse: 45232.0469 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1141/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7865 - mse: 46378.7734 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1142/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0898 - mse: 43465.8594 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1143/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5434 - mse: 47146.1797 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1144/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.8980 - mse: 45167.9805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1145/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.5185 - mse: 41864.4805 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1146/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.2449 - mse: 42256.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1147/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.7343 - mse: 43198.0117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1148/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.4450 - mse: 45088.2617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1149/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.1120 - mse: 45864.0352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1150/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0657 - mse: 43160.5898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1151/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5933 - mse: 46370.1367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.8004e-05\n",
      "Epoch 1152/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2530 - mse: 43592.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1153/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4095 - mse: 43482.8242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1154/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2326 - mse: 45199.4414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1155/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1735 - mse: 43426.0117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1156/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0446 - mse: 42660.1406 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1157/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.1360 - mse: 46163.0156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1158/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5198 - mse: 44732.9883 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1159/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 105.2900 - mse: 41870.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1160/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 115.1085 - mse: 49035.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1161/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.9553 - mse: 42328.9023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1162/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.9459 - mse: 47989.2422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1163/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.4592 - mse: 43143.9609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1164/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.6153 - mse: 47156.4922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1165/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3577 - mse: 42416.7617 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1166/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7839 - mse: 46708.2422 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1167/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.0351 - mse: 43704.7500 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1168/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.1881 - mse: 43389.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1169/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.2824 - mse: 45267.1172 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1170/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3096 - mse: 43567.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1171/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2024 - mse: 44989.3242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1172/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5134 - mse: 46280.6836 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1173/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9749 - mse: 44851.0859 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1174/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.0877 - mse: 43490.4102 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1175/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1349 - mse: 43407.5547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1176/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9556 - mse: 44180.7031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1177/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 106.7114 - mse: 41001.5391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1178/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3959 - mse: 43784.3945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1179/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.8440 - mse: 43607.7812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1180/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.4851 - mse: 45504.4219 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1181/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.3984 - mse: 42762.8516 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1182/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6245 - mse: 43524.2578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1183/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8500 - mse: 44737.5391 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1184/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1113 - mse: 44831.0508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1185/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9667 - mse: 45781.5586 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1186/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2785 - mse: 43461.6055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1187/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.2954 - mse: 44215.2930 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1188/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5778 - mse: 47041.3398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1189/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.7815 - mse: 47090.9922 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1190/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.4508 - mse: 43492.2656 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1191/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.5873 - mse: 44235.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1192/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.8949 - mse: 46138.7031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1193/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.5490 - mse: 46379.3281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1194/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3481 - mse: 44718.3281 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1195/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.0159 - mse: 40602.9648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1196/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1559 - mse: 44729.1562 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1197/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7644 - mse: 44762.0234 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1198/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.9978 - mse: 45396.6133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1199/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.1167 - mse: 43789.6992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1200/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.5675 - mse: 47326.8398 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1201/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.0816 - mse: 44323.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.3803e-05\n",
      "Epoch 1202/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.2149 - mse: 42394.2812 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1203/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7014 - mse: 44673.5508 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1204/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 105.4950 - mse: 41316.1055 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1205/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4115 - mse: 46197.5547 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1206/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.1754 - mse: 46049.3633 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1207/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.6349 - mse: 44397.2891 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1208/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3683 - mse: 41615.6328 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1209/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6114 - mse: 42853.8086 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1210/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 103ms/step - loss: 109.9319 - mse: 45868.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1211/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2851 - mse: 43377.2969 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1212/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8289 - mse: 45111.6289 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1213/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 104.7131 - mse: 41532.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1214/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8995 - mse: 43841.4141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1215/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.4014 - mse: 42996.6367 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1216/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3271 - mse: 45022.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1217/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.7058 - mse: 46802.6484 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1218/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1638 - mse: 45253.3203 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1219/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.9955 - mse: 46110.8125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1220/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.1203 - mse: 46985.5664 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1221/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.4330 - mse: 47813.1641 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1222/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3107 - mse: 42837.2031 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1223/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.3938 - mse: 42491.8242 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1224/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.2433 - mse: 45478.8477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1225/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.5334 - mse: 46922.5156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1226/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.2029 - mse: 47165.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1227/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.8121 - mse: 43715.6602 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1228/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.2077 - mse: 42138.1250 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1229/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.9389 - mse: 47963.2383 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1230/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.8651 - mse: 44371.9609 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1231/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.0653 - mse: 45188.8750 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1232/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.9622 - mse: 48139.0273 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1233/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.5630 - mse: 46674.5938 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1234/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.8286 - mse: 44347.1992 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1235/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.8370 - mse: 46035.0977 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1236/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 105.6295 - mse: 42240.4688 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1237/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3647 - mse: 44087.1016 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1238/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5202 - mse: 46383.3477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1239/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.6930 - mse: 47075.4648 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1240/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.6209 - mse: 44746.5117 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1241/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 114.7291 - mse: 48889.3359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1242/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1259 - mse: 44093.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1243/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 55ms/step - loss: 107.3798 - mse: 42527.3906 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1244/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.7111 - mse: 45310.2070 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1245/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 113.7845 - mse: 47043.3828 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1246/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.8492 - mse: 44701.5703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1247/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0972 - mse: 42808.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1248/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.4693 - mse: 43394.0781 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1249/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.3731 - mse: 44699.4023 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1250/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.7809 - mse: 44528.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1251/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6331 - mse: 46477.3477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 2.0233e-05\n",
      "Epoch 1252/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.5564 - mse: 45285.5156 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1253/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 107.8803 - mse: 44113.1133 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1254/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.6591 - mse: 42295.0898 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1255/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 114.0821 - mse: 47182.7266 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1256/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 114.7796 - mse: 48283.9414 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1257/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.9199 - mse: 44291.3711 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1258/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2350 - mse: 46114.1445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1259/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.9410 - mse: 44683.3477 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1260/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0443 - mse: 43946.0703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1261/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 112.2121 - mse: 45666.0703 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1262/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4714 - mse: 45528.3359 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1263/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 288ms/step - loss: 108.8299 - mse: 43781.8555 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1264/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.5950 - mse: 46816.6445 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1265/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.3485 - mse: 45208.3438 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1266/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 110.1511 - mse: 44658.9141 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1267/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 112.6262 - mse: 45868.5625 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1268/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.2677 - mse: 42963.2461 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1269/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.0920 - mse: 43107.3125 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1270/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 106.0107 - mse: 41668.9336 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1271/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 109.3503 - mse: 44246.6953 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1272/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 110.4165 - mse: 45130.0000 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1273/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 107.6258 - mse: 41765.7578 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1274/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.2207 - mse: 45800.8164 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1275/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.8348 - mse: 45921.7305 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1276/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 111.0769 - mse: 44823.8945 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1277/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 111.4641 - mse: 45187.5352 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1278/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 109.1597 - mse: 44122.2695 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1279/2500\n",
      "\u001b[1m510/510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 108.3077 - mse: 43758.0195 - val_loss: 114.8224 - val_mse: 50637.6250 - learning_rate: 1.7198e-05\n",
      "Epoch 1280/2500\n",
      "\u001b[1m179/510\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m59:39\u001b[0m 11s/step - loss: 114.7568 - mse: 49024.1641"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=train_X, y=train_y, epochs = 2500, verbose = True, batch_size=1, validation_data=(test_X, test_y), callbacks=_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualiseFits(fits, validationData = True):\n",
    "    fig, axs = plt.subplots(2, 2, figsize = (40, 20))\n",
    "\n",
    "    axs[0][0].plot(fits.history['loss'], label = \"Conventional NN Train EPE\")\n",
    "    axs[0][0].legend()\n",
    "    axs[0][0].set_xlabel(\"Epochs\")\n",
    "    axs[0][0].set_ylabel(\"EPE (log Scaled)\")\n",
    "    axs[0][0].set_yscale('log')\n",
    "    axs[0][0].grid(True)\n",
    "\n",
    "    axs[1][0].plot(fits.history['loss'], label = \"Conventional NN Train EPE\")\n",
    "    axs[1][0].legend()\n",
    "    axs[1][0].set_xlabel(\"Epochs\")\n",
    "    axs[1][0].set_ylabel(\"EPE\")\n",
    "    axs[1][0].grid(True)\n",
    "\n",
    "    axs[0][1].plot(fits.history['mse'], label = \"Conventional NN Train MSE\")\n",
    "    axs[0][1].legend()\n",
    "    axs[0][1].set_xlabel(\"Epochs\")\n",
    "    axs[0][1].set_ylabel(\"MSE\")\n",
    "    axs[0][1].grid(True)\n",
    "\n",
    "    axs[1][1].plot(fits.history['mse'], label = \"Conventional NN Train MSE\")\n",
    "    axs[1][1].legend()\n",
    "    axs[1][1].set_xlabel(\"Epochs\")\n",
    "    axs[1][1].set_ylabel(\"MSE (log scaled)\")\n",
    "    axs[1][1].set_yscale('log')\n",
    "    axs[1][1].grid(True)\n",
    "    \n",
    "    if validationData:\n",
    "        axs[0][0].plot(fits.history['val_loss'], label = \"Conventional NN Train EPE validation\")\n",
    "        axs[1][0].plot(fits.history['val_loss'], label = \"Conventional NN Train EPE validation\")\n",
    "        axs[0][1].plot(fits.history['val_mse'], label = \"Conventional NN Train MSE validation\")\n",
    "        axs[1][1].plot(fits.history['val_mse'], label = \"Conventional NN Train MAE validation\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiseFits(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(train_X[0].numpy().reshape(1, 2, 436, 1024, 1))\n",
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiser.visualiseOpticalFlow(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomImagePair =tf.random.uniform(\n",
    "    shape = (5, 2, 436, 1024, 1),\n",
    "    minval=0,\n",
    "    maxval=255,\n",
    "    dtype=tf.dtypes.float32,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize = (20, 10))\n",
    "\n",
    "ax[0].imshow(randomImagePair[0, 0, :, :, :], cmap = 'gray')\n",
    "ax[1].imshow(randomImagePair[0, 0, :, :, :], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(randomImagePair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiser.visualiseOpticalFlow(flow=result[4].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PIOFE-Unrolling-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
